{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48281fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"words.txt\") as f:\n",
    "    words = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0d29bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ls = []\n",
    "for word in words:\n",
    "    if word and \" \" not in word and \"/\" not in word and \",\" not in word and \"\\n\" not in word and \".\" not in word:\n",
    "        new_ls.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b182f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ls[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193e7590",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"word_list.txt\",\"w\") as f:\n",
    "    for word in new_ls:\n",
    "        f.write(word + \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a6026ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_ls = []\n",
    "with open(\"word_list.txt\",\"r\") as f:\n",
    "    content = f.read()\n",
    "request_ls = content.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [04:02<00:00,  1.74it/s]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "meaning_ls = []\n",
    "def get_word_meanings(words: str):\n",
    "    word_list = words.split(\",\")\n",
    "    dictionary_api = \"https://api.dictionaryapi.dev/api/v2/entries/en/\"\n",
    "    words_meanings = []\n",
    "\n",
    "    for word in word_list:\n",
    "        word = word.strip()\n",
    "        response = requests.get(dictionary_api + word)\n",
    "        if response.status_code != 200:\n",
    "            words_meanings.append(f\"{word} - not found\")\n",
    "            continue\n",
    "\n",
    "        data = response.json()\n",
    "\n",
    "        # format: word \\n phonetic \\n \";\".join all meanings\n",
    "        entry = data[0]\n",
    "        text = f\"{entry.get('word', '')}\\n{entry.get('phonetic', '')}\\n\"\n",
    "\n",
    "        for meaning in entry.get(\"meanings\", []):\n",
    "            for definition in meaning.get(\"definitions\", []):\n",
    "                text += definition.get(\"definition\", \"\") + \"; \"\n",
    "\n",
    "        words_meanings.append(text.strip())\n",
    "\n",
    "    return words_meanings\n",
    "\n",
    "for word in tqdm(request_ls):\n",
    "    meaning = get_word_meanings(word)\n",
    "    meaning_ls.append(meaning)\n",
    "    time.sleep(0.5)  # to avoid hitting the API rate limit\n",
    "    \n",
    "with open(\"meanings.txt\",\"a\",encoding=\"utf-8\") as f:\n",
    "    f.write(meaning[0] + \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5d9a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ls = [i[0] for i in meaning_ls if \"not found\" not in i[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f0a47b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ls = [i[0] for i in meaning_ls if \"not found\" not in i[0]]\n",
    "with open(\"meanings.txt\",\"w\",encoding=\"utf-8\") as f:\n",
    "    for meaning in new_ls:\n",
    "        f.write(meaning + \"\\n----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25366c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 413 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 1, got 16 embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   4%|▍         | 1/26 [00:05<02:23,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 2, got 16 embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   8%|▊         | 2/26 [00:08<01:29,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 3, got 16 embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  12%|█▏        | 3/26 [00:10<01:09,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 4, got 16 embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  15%|█▌        | 4/26 [00:12<01:00,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 5, got 16 embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  19%|█▉        | 5/26 [00:15<00:55,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 6, got 16 embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  23%|██▎       | 6/26 [00:17<00:50,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 7, got 16 embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  27%|██▋       | 7/26 [00:19<00:46,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 8, got 16 embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  31%|███       | 8/26 [00:22<00:44,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 9, got 16 embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  35%|███▍      | 9/26 [00:24<00:41,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 10, got 16 embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  38%|███▊      | 10/26 [00:26<00:37,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 11, got 16 embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  42%|████▏     | 11/26 [00:29<00:35,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 12, got 16 embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  46%|████▌     | 12/26 [00:31<00:33,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 13, got 16 embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  50%|█████     | 13/26 [00:33<00:30,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 14, got 16 embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  54%|█████▍    | 14/26 [00:36<00:28,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 15, got 16 embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  58%|█████▊    | 15/26 [00:38<00:25,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 16, got 16 embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  62%|██████▏   | 16/26 [00:40<00:24,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 17, got 16 embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  65%|██████▌   | 17/26 [00:43<00:21,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 18, got 16 embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  69%|██████▉   | 18/26 [00:45<00:19,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 19, got 16 embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  73%|███████▎  | 19/26 [00:48<00:16,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 20, got 16 embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  77%|███████▋  | 20/26 [00:50<00:14,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 21, got 16 embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  81%|████████  | 21/26 [00:52<00:11,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 22, got 16 embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  85%|████████▍ | 22/26 [00:55<00:09,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 23, got 16 embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  88%|████████▊ | 23/26 [00:57<00:06,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 24, got 16 embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  92%|█████████▏| 24/26 [00:59<00:04,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 25, got 16 embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  96%|█████████▌| 25/26 [01:02<00:02,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 26, got 13 embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 26/26 [01:04<00:00,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings collected: 413\n",
      "Embeddings shape: (413, 1024)\n",
      "Embeddings processed successfully!\n",
      "L2 normalized shape: (413, 1024)\n",
      "MinMax normalized shape: (413, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Get embeddings for all texts in new_ls with batching\n",
    "def get_embeddings_batch(texts, batch_size=16):\n",
    "    \"\"\"Get embeddings for a batch of texts using Replicate proxy\"\"\"\n",
    "    url = \"https://itp-ima-replicate-proxy.web.app/api/create_n_get\"\n",
    "    auth_token = \"\"\n",
    "    model_name = \"beautyyuyanli/multilingual-e5-large:a06276a89f1a902d5fc225a9ca32b6e8e6292b7f3b136518878da97c458e2bad\"\n",
    "    \n",
    "    # Clean texts - remove brackets, quotes, backslashes\n",
    "    cleaned_texts = [re.sub(r\"[\\[\\]\\\\\\'\\\"]\", '', text) for text in texts]\n",
    "    \n",
    "    data = {\n",
    "        \"version\": model_name,\n",
    "        \"input\": {\n",
    "            \"texts\": str(cleaned_texts).replace('\\'', '\\\"'),\n",
    "            \"batch_size\": batch_size,\n",
    "            \"normalize_embeddings\": False\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {auth_token}\"\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return np.array(response.json()['output'])\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "        return None\n",
    "\n",
    "# Process all 412 texts with batching\n",
    "print(f\"Processing {len(new_ls)} texts...\")\n",
    "batch_size = 16\n",
    "all_embeddings = []\n",
    "\n",
    "# Split into batches\n",
    "for i in tqdm(range(0, len(new_ls), batch_size), desc=\"Processing batches\"):\n",
    "    batch_texts = new_ls[i:i + batch_size]\n",
    "    \n",
    "    try:\n",
    "        batch_embeddings = get_embeddings_batch(batch_texts, batch_size)\n",
    "        \n",
    "        if batch_embeddings is not None:\n",
    "            all_embeddings.extend(batch_embeddings)\n",
    "            print(f\"Processed batch {i//batch_size + 1}, got {len(batch_embeddings)} embeddings\")\n",
    "        else:\n",
    "            print(f\"Failed to get embeddings for batch {i//batch_size + 1}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {i//batch_size + 1}: {e}\")\n",
    "    \n",
    "    # Sleep to avoid rate limiting\n",
    "    time.sleep(1.0)\n",
    "\n",
    "print(f\"Total embeddings collected: {len(all_embeddings)}\")\n",
    "\n",
    "# Convert to numpy array\n",
    "if all_embeddings:\n",
    "    embeddings = np.array(all_embeddings)\n",
    "    print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "    \n",
    "    # L2 normalization\n",
    "    l2_normalized_embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "    \n",
    "    # MinMax normalization\n",
    "    minmax_normalized_embeddings = (embeddings - embeddings.min(axis=0)) / (embeddings.max(axis=0) - embeddings.min(axis=0))\n",
    "    \n",
    "    print(\"Embeddings processed successfully!\")\n",
    "    print(f\"L2 normalized shape: {l2_normalized_embeddings.shape}\")\n",
    "    print(f\"MinMax normalized shape: {minmax_normalized_embeddings.shape}\")\n",
    "else:\n",
    "    print(\"No embeddings were successfully collected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79a76669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting embeddings to JavaScript formats...\n",
      "Embeddings exported to embeddings.js\n",
      "File size: 9148.6 KB\n",
      "HTML script exported to embeddings_script.html\n",
      "\n",
      "✅ All exports completed!\n",
      "Embeddings shape: (413, 1024)\n",
      "Total data points: 422912\n",
      "HTML script exported to embeddings_script.html\n",
      "\n",
      "✅ All exports completed!\n",
      "Embeddings shape: (413, 1024)\n",
      "Total data points: 422912\n"
     ]
    }
   ],
   "source": [
    "# Export embeddings to JavaScript format\n",
    "import json\n",
    "\n",
    "# Option 1: Create a JavaScript file with a variable (Recommended)\n",
    "def export_to_js_file(embeddings, filename=\"embeddings.js\", var_name=\"embeddings\"):\n",
    "    \"\"\"Export embeddings as a JavaScript variable in a .js file\"\"\"\n",
    "    embeddings_list = embeddings.tolist()  # Convert numpy array to list\n",
    "    \n",
    "    js_content = f\"// Generated embeddings data\\n\"\n",
    "    js_content += f\"// Shape: {embeddings.shape}\\n\"\n",
    "    js_content += f\"const {var_name} = {json.dumps(embeddings_list)};\\n\\n\"\n",
    "    js_content += f\"// Export for use in other files\\n\"\n",
    "    js_content += f\"if (typeof module !== 'undefined' && module.exports) {{\\n\"\n",
    "    js_content += f\"    module.exports = {var_name};\\n\"\n",
    "    js_content += f\"}}\\n\"\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(js_content)\n",
    "    \n",
    "    print(f\"Embeddings exported to {filename}\")\n",
    "    print(f\"File size: {len(js_content) / 1024:.1f} KB\")\n",
    "\n",
    "# Option 2: Create JSON file (for fetch/import)\n",
    "def export_to_json(embeddings, filename=\"embeddings.json\"):\n",
    "    \"\"\"Export embeddings as JSON file\"\"\"\n",
    "    data = {\n",
    "        \"embeddings\": embeddings.tolist(),\n",
    "        \"shape\": embeddings.shape,\n",
    "        \"length\": len(embeddings),\n",
    "        \"embedding_dim\": embeddings.shape[1] if len(embeddings.shape) > 1 else 0\n",
    "    }\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f, separators=(',', ':'))  # Compact format\n",
    "    \n",
    "    print(f\"Embeddings exported to {filename}\")\n",
    "\n",
    "# Option 3: Create HTML script tag (for direct inclusion)\n",
    "def export_to_html_script(embeddings, filename=\"embeddings_script.html\", var_name=\"embeddings\"):\n",
    "    \"\"\"Export as HTML script tag\"\"\"\n",
    "    embeddings_list = embeddings.tolist()\n",
    "    \n",
    "    html_content = f\"<!-- Include this in your HTML file -->\\n\"\n",
    "    html_content += f\"<script>\\n\"\n",
    "    html_content += f\"const {var_name} = {json.dumps(embeddings_list)};\\n\"\n",
    "    html_content += f\"console.log('Loaded embeddings:', {var_name}.length);\\n\"\n",
    "    html_content += f\"</script>\\n\"\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(html_content)\n",
    "    \n",
    "    print(f\"HTML script exported to {filename}\")\n",
    "\n",
    "# Export using all methods if embeddings exist\n",
    "if 'embeddings' in locals() and embeddings is not None:\n",
    "    print(\"Exporting embeddings to JavaScript formats...\")\n",
    "    \n",
    "    # Method 1: JavaScript file (most flexible)\n",
    "    export_to_js_file(embeddings, \"embeddings.js\", \"wordEmbeddings\")\n",
    "    \n",
    "    # # Method 2: JSON file (for loading via fetch)\n",
    "    # export_to_json(embeddings, \"embeddings.json\")\n",
    "    \n",
    "    # Method 3: HTML script (for direct inclusion)\n",
    "    export_to_html_script(embeddings, \"embeddings_script.html\", \"wordEmbeddings\")\n",
    "    \n",
    "    print(\"\\n✅ All exports completed!\")\n",
    "    print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "    print(f\"Total data points: {embeddings.size}\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No embeddings found. Run the previous cell first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
